{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from egnn_pytorch import EGNN_Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import gzip\n",
    "import math\n",
    "plosses=[]\n",
    "class RadialBasisFunction(torch.nn.Module):\n",
    "    def __init__(self, num_basis=128, cutoff=5.0):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        self.register_buffer('mu', torch.linspace(0, cutoff, num_basis))\n",
    "        self.gamma = 12 # You can tune this\n",
    "\n",
    "    def forward(self, distances):\n",
    "        distances = distances.unsqueeze(-1) # shape (N, N, 1)\n",
    "        rbf = torch.exp(-self.gamma * (distances - self.mu)**2)\n",
    "        return rbf # shape (N, N, num_basis)\n",
    "\n",
    "def pairwise_distances(x):\n",
    "    diff = x.unsqueeze(1) -x.unsqueeze(0)\n",
    "    dist = torch.norm(diff,dim=-1)\n",
    "    return dist\n",
    "# Example of aggregation function\n",
    "def aggregate_rbf_features(rbf_features):\n",
    "# Simple global mean aggregation\n",
    "    global_features = rbf_features.mean(dim=(0,1))\n",
    "    return global_features\n",
    "\n",
    "# After EGNN outputs embeddings (h_i, x_i):\n",
    "#distances = pairwise_distances(out1[1])\n",
    "#rbf = RadialBasisFunction()(distances)\n",
    "class TinyRegressor(nn.Module):\n",
    "    def __init__(self, in_channels=3,lin_channels=dim):\n",
    "        super().__init__()\n",
    "        #self.encoding = A\n",
    "        #self.mha = mha\n",
    "        self.conv1 = nn.Conv1d(in_channels, 15, 1, padding = 0)\n",
    "        self.conv2 = nn.Conv1d(15, 3, 3, padding=1)\n",
    "        #self.conv3 = nn.Conv1d(3, 2, 2, padding=0)\n",
    "        self.conv4 = nn.Conv1d(3, 1, 1, padding=0)\n",
    "        self.out  = nn.Linear(1, 1)\n",
    "        self.conv5 = nn.Conv1d(1, 1, 3, padding = (3 - 1) // 2)\n",
    "        #self.conv6 = nn.Conv1d(1, 1, 1, padding = (1 - 1) // 2)\n",
    "\n",
    "        #self.softmax=nn.Softmax()\n",
    "            #nn.ReLU(),\n",
    "        #nn.Conv1d(3,1,1, padding=1),\n",
    "            #nn.ReLU()\n",
    "        #)\n",
    "        self.relu=nn.PReLU()#Softmax()#ReLU()\n",
    "        #self.pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        #self.out1  = nn.Linear(6, 1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x=self.mha(self.encoding(x))\n",
    "        x=self.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x=self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.out(x.T)\n",
    "        \n",
    "        #x = self.conv3(x)\n",
    "        #x=self.relu(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        #x = self.conv4(x)\n",
    "        #x = self.softmax(x)\n",
    "        #x=self.out1(x)\n",
    "        #x = self.pool(x).flatten(1)   # (B, 32)\n",
    "        #x=self.out(x)#self.relu(x)\n",
    "        return x#self.relu(x)\n",
    "\n",
    "       # (B, 1)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Helper to load one sample and keep it in the graph\n",
    "# ---------------------------------------------------------------\n",
    "def load_example(path, device):\n",
    "    a = np.load(path, allow_pickle=True)\n",
    "    zs, xs, ys = a[\"z\"], a[\"pos\"], a[\"pks\"]\n",
    "    # convert to torch, keep autograd graph\n",
    "    zs_t = torch.from_numpy(zs.astype(np.int32)).to(device)       # for embedding lookups\n",
    "    xs_t = torch.from_numpy(xs).to(device).float()                # your float features\n",
    "    ys_t = torch.from_numpy(ys).to(device).float()                # your targets\n",
    "    return zs_t, xs_t, ys_t\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Build your models, criterion, device\n",
    "# ---------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#net   = YourBackboneNet(...).to(device)\n",
    "#mha   = nn.MultiheadAttention(embed_dim=..., num_heads=...).to(device)\n",
    "#model = YourScalarHead(...).to(device)\n",
    "def egnn(dim=6):#,learning_rate=.001):\n",
    "\n",
    "    net=EGNN_Network(dim=dim,\n",
    "    depth=1,\n",
    "    num_positions=500, #no\n",
    "    num_tokens=100,\n",
    "    num_nearest_neighbors=1,\n",
    "    #coor_weights_clamp_value = 2,\n",
    "    norm_coors=True)\n",
    "\n",
    "    #optimizer= torch.optim.Adam(list(net.parameters()) + list(model.parameters()), lr=learning_rate)\n",
    "    \n",
    "    #criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "\n",
    "    return net#, optimizer, criterion\n",
    "dim=10\n",
    "criterion = nn.L1Loss()\n",
    "model = TinyRegressor(in_channels=128+dim,lin_channels=dim).to(device)\n",
    "net=egnn(dim=dim).to(device)\n",
    "A = PositionalEncoding(dim)\n",
    "mha = SimpleMultiheadAttention(dim,dim).to(device) #6 is the dim\n",
    "torch.manual_seed(0)\n",
    "vlosses=[]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Single optimizer with two param‐groups\n",
    "# ---------------------------------------------------------------\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": net.parameters(),   \"lr\": 1e-4},\n",
    "    {\"params\": mha.parameters(),   \"lr\": 1e-2},\n",
    "    {\"params\": model.parameters(), \"lr\": 1e-3},\n",
    "],weight_decay=1e-5)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Get file list\n",
    "# ---------------------------------------------------------------\n",
    "paths = sorted(glob.glob(\"/home/jrhoernschemeyer/Desktop/data_prep/inputs/*.npz\"))[:100]\n",
    "tpaths=sorted(glob.glob(\"/home/jrhoernschemeyer/Desktop/data_prep/inputs/*.npz\"))[100:200]\n",
    "epoch_losses = []\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4) Training loop\n",
    "# ---------------------------------------------------------------\n",
    "for epoch in range(30):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    net.train()\n",
    "    mha.train()\n",
    "    model.train()\n",
    "    plosses.append(epoch_losses)\n",
    "    vlosses.append(vepoch_losses)\n",
    "    epoch_losses = []\n",
    "    vepoch_losses = []\n",
    "    #vlosses=[]\n",
    "\n",
    "    # for brevity, we’ll do just the first 2 files as before\n",
    "    for path in list(np.array(paths)[np.random.permutation(len(paths))]):#np.shuffle(paths):\n",
    "        # load the raw arrays\n",
    "        a  = np.load(path, allow_pickle=True)\n",
    "        zs = a[\"z\"]       # array of length-N residues, each zs[i] is a (Li,3) array\n",
    "        xs = a[\"pos\"]     # (N,?) array of floats\n",
    "        ys = a[\"pks\"]     # (N,) array of targets\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outs = []\n",
    "\n",
    "        # now iterate residue-by-residue, converting each to a proper tensor\n",
    "        for z_i, x_i, y_i in zip(zs, xs, ys):\n",
    "            # convert this one example\n",
    "            # — for z: a variable-length coordinate array\n",
    "            z_t = torch.from_numpy(z_i[0].astype(np.int32)) \\\n",
    "                       .unsqueeze(0) \\\n",
    "                       .to(device)            # [1, Li, 3] or however your net expects it\n",
    "\n",
    "            # — for x: your feature array, assumed float\n",
    "            x_t = torch.from_numpy(x_i).unsqueeze(0).float().to(device)  # [1, ?]\n",
    "\n",
    "            # forward pass\n",
    "            out1, _         = net(z_t, x_t)           # adapt to your signature\n",
    "            attn_out,__     = mha(A(out1[0]))\n",
    "            distances = pairwise_distances(_)\n",
    "            rbf = RadialBasisFunction()(distances)\n",
    "            global_rbf_features = aggregate_rbf_features(rbf)\n",
    "           \n",
    "\n",
    "            \n",
    "            #out             = attn_out#out1#torch.matmul(__,attn_out)\n",
    "            global_node_features    = attn_out.max(dim=0)[0]   # [features]#\n",
    "            #global_node_features = out\n",
    "            # Concatenate node embeddings and RBF features\n",
    "            global_embedding = torch.hstack([global_node_features, global_rbf_features]).unsqueeze(2)\n",
    "\n",
    "            # Predict energy scalar\n",
    "            energy_pred = model(global_embedding.permute(2,1,0))\n",
    "            #attn_out,_ =       mha(A(out1[0]))\n",
    "            #embedding       = global_node_feats # [features, 1]\n",
    "            #energy_pred     = model(embedding.permute(0,2,1))#.unsqueeze(0))           # [1,1] or similar\n",
    "            outs.append(torch.mean(energy_pred))#.squeeze())\n",
    "\n",
    "        # stack and compute loss\n",
    "        preds = torch.hstack(outs)  \n",
    "        #preds=model.conv5(mha(A(preds.unsqueeze(1)))[0].permute(1,2,0)) \n",
    "        #preds=model.conv6(preds)[0]\n",
    "        preds = model.conv5(preds.unsqueeze(0).unsqueeze(1))[0][0]          # [N]\n",
    "        target = torch.from_numpy(ys).float().to(device)\n",
    "\n",
    "        loss = criterion(preds, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "        #print(f\"Epoch {epoch}\")\n",
    "    \n",
    "############################\n",
    "    net.eval()\n",
    "    mha.eval()\n",
    "    model.eval()\n",
    "    vlosses.append(vepoch_losses)\n",
    "        # for brevity, we’ll do just the first 2 files as before\n",
    "    for path in tpaths:#np.shuffle(paths):\n",
    "        # load the raw arrays\n",
    "        a  = np.load(path, allow_pickle=True)\n",
    "        zs = a[\"z\"]       # array of length-N residues, each zs[i] is a (Li,3) array\n",
    "        xs = a[\"pos\"]     # (N,?) array of floats\n",
    "        ys = a[\"pks\"]     # (N,) array of targets\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        outs = []\n",
    "\n",
    "        # now iterate residue-by-residue, converting each to a proper tensor\n",
    "        for z_i, x_i, y_i in zip(zs, xs, ys):\n",
    "            # convert this one example\n",
    "            # — for z: a variable-length coordinate array\n",
    "            z_t = torch.from_numpy(z_i[0].astype(np.int32)) \\\n",
    "                    .unsqueeze(0) \\\n",
    "                    .to(device)            # [1, Li, 3] or however your net expects it\n",
    "\n",
    "            # — for x: your feature array, assumed float\n",
    "            x_t = torch.from_numpy(x_i).unsqueeze(0).float().to(device)  # [1, ?]\n",
    "\n",
    "            # forward pass\n",
    "            out1, _         = net(z_t, x_t)           # adapt to your signature\n",
    "            attn_out,__     = mha(A(out1[0]))\n",
    "            distances = pairwise_distances(_)\n",
    "            rbf = RadialBasisFunction()(distances)\n",
    "            global_rbf_features = aggregate_rbf_features(rbf)\n",
    "        \n",
    "\n",
    "            \n",
    "            out             = attn_out#out1#torch.matmul(__,attn_out)\n",
    "            global_node_features    = out.max(dim=0)[0]   # [features]#\n",
    "            #global_node_features = out\n",
    "            # Concatenate node embeddings and RBF features\n",
    "            global_embedding = torch.hstack([global_node_features, global_rbf_features]).unsqueeze(2)\n",
    "\n",
    "            # Predict energy scalar\n",
    "            energy_pred = model(global_embedding.permute(2,1,0))\n",
    "            #attn_out,_ =       mha(A(out1[0]))\n",
    "            #embedding       = global_node_feats # [features, 1]\n",
    "            #energy_pred     = model(embedding.permute(0,2,1))#.unsqueeze(0))           # [1,1] or similar\n",
    "            outs.append(torch.mean(energy_pred))#.squeeze())\n",
    "\n",
    "        # stack and compute loss\n",
    "        preds = torch.hstack(outs)  \n",
    "        #preds=model.conv5(mha(A(preds.unsqueeze(1)))[0].permute(1,2,0)) \n",
    "        #preds=model.conv5(preds.unsqueeze(1)))[0].permute(1,2,0\n",
    "        #preds=model.conv6(preds)[0]\n",
    "        preds = model.conv5(preds.unsqueeze(0).unsqueeze(1))[0][0]          # [N]\n",
    "        target = torch.from_numpy(ys).float().to(device)\n",
    "        \n",
    "        loss = criterion(preds, target)\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "\n",
    "        vepoch_losses.append(loss.item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    avg = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f\" → avg loss: {avg:.4f}\\n\")\n",
    "\n",
    "    avg = sum(vepoch_losses) / len(vepoch_losses)\n",
    "    print(f\" → avg loss: {avg:.4f}\\n\")\n",
    "\n",
    "\n",
    "plt.plot(np.array([plosses[1:]]).flatten())\n",
    "plt.show()\n",
    "plt.plot(np.array([vlosses[1:]]).flatten())\n",
    "\n",
    "plt.title(f\"now conv1ding the preds. dim4. 2gamma.1e4 . mean egnn {egnn} \\n {model}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
